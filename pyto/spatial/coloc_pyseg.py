"""
Generating, reading and preprocessing of pyseg colocalization data.

Pyto specific colocalization methods are in coloc_table_read.py.
 
# Author: Vladan Lucic
# $Id$
"""

__version__ = "$Revision$"

import abc
import os
import subprocess
import pickle

import numpy as np
import pandas as pd

import pyto
from pyto.io.pandas_io import PandasIO
from . import coloc_functions as col_func


class ColocPyseg(abc.ABC):
    """Abstract class that provides pyseg colocalization methods.

    Meant to be inherited by ColocAnalysis.
    """

    @abc.abstractmethod
    def __init__(self):
        pass

    @classmethod
    def colocalize_run(
            cls, coloc_case, psets, script_name, distances, n_sim, root_path,
            mode, column_radius_factor, pixel_size=1.,
            python_cmd='python3', debug=False):
        """
        Runs PySeg colocalization script to generate raw colocalization data.

        Used for the case where particle sets are generated by PySeg and 
        a PySeg script is used to run colocalization. See 
        ColocLite.colocalize() for running colocalization by Pyto.  

        Prepares variables that are passed to the colocalization script (the
        script is modified from the PySeg version so that it accepts 
        arguments). The script is run in parallel, for each distance 
        separately.

        Argumens passed to the script:
          - argv[0]: script name
          - argv[1], argv[3], argv[5]: particle set files 
          - argv[2], argv[4], argv[6]: particle set ids 
          - argv[7]: particle shape
          - argv[8]: path to the raw colocalization data directory 
          - argv[9]: raw colocalization data stem
          - argv[10]: colocalization distance 
          - argv[11]: columns distance 
          - argv[12]: n simulations
          - argv[13]: pixel size [nm]

        Arguments:
          - coloc_case: colocalization name with the prepended number of 
          colocalizations (e.g. '3_setX_setY_setZ', '2_pre_post')
          - pset: module containing paths to particle set star files and ids_1
          - script_name: path to PySeg colocalization script 
          - distances: list of colocalization distances (in nm)
          - n_sim: number of simulations
          - root path: raw colocalization results root path
          - mode: defines how to form the paths to the raw colocalization data
          (see extract_data() doc)
          - column_radius_factor: column radius is obtained by multiplying 
          the colocalization distance by this factor
          - pixel_size: pixel size [nm]
          - python_cmd: python command
          - debug: debug flag, currently not used
        """

        # parse and check coloc_case
        out_base_split = coloc_case.split('_')
        n_coloc = int(out_base_split[0])
        if len(out_base_split)-1 != n_coloc:
            raise ValueError(
                "Variable out_base has {} parts but starts with {}".format(
                    len(out_base_split)-1, n_coloc))
        name = coloc_case.split('_', 1)[1]

        # assign partice sets variables
        in_star_1 = getattr(psets, 'in_star_' + out_base_split[1])
        l_id1 = getattr(psets, 'l_id_' + out_base_split[1])
        in_star_2 = getattr(psets, 'in_star_' + out_base_split[2])
        l_id2 = getattr(psets, 'l_id_' + out_base_split[2])
        if n_coloc == 3:
           in_star_3 = getattr(psets, 'in_star_' + out_base_split[3])
           l_id3 = getattr(psets, 'l_id_' + out_base_split[3])
        elif n_coloc ==2:
           in_star_3 = getattr(psets, 'in_star_' + out_base_split[2])
           l_id3 = getattr(psets, 'l_id_' + out_base_split[2])
        else:
            raise ValueError("Variable out_base has to start with 2 or 3")

        # common arguments
        args_begin = [python_cmd, script_name]
        args_begin += [
            in_star_1, str(l_id1), in_star_2, str(l_id2), in_star_3, str(l_id3)]
        args_begin += [psets.in_part]

        #
        base_paths = col_func.get_raw_coloc_bases(
            name=name, distances=distances, mode=mode, n_sim=n_sim,
            n_coloc=n_coloc, column_radius_factor=column_radius_factor)
        
        for dist, b_path in zip(distances, base_paths):
            column_radius = column_radius_factor * dist

            # add arguments that depend on distance
            path = os.path.normpath(os.path.join(root_path, b_path))
            out_dir, out_stem = os.path.split(path)
            args = args_begin + [
                out_dir, out_stem, str(dist), str(column_radius),
                str(n_sim), str(pixel_size)]

            # make log path
            log_name = \
                f'{n_coloc}_{name}_{dist}_{column_radius}_sim-{n_sim}.log'
            #out_dir = os.path.join(
            #    out_root_path, out_base, f'dist-{dist}_cr-{column_radius}')
            #out_dir = os.path.normpath(out_dir)
            #out_stem =  '{}_sim-{}'.format(out_base, n_simulations)
            #log_file_name = os.path.join(out_dir, out_stem + '.log')
            log_fd = open(log_name, 'w')

            # run
            if debug:
                print(args)
            subprocess.Popen(args, stdout=log_fd, stderr=log_fd)
            # in some cases necessary for subprocesses to run (don't know why)
            time.sleep(5)
 
    @classmethod
    def extract_multi(
            cls, names, distances, in_path, mode, n_sim=None, columns=None,
            p_values=True, random_stats=False, save=False,
            force=False,  dir_='.', save_formats=['pkl', 'json'], verbose=True,
            join_suffix='data', individual_suffix='data_syn'):
        """Converts raw pyseg colocalization results to pandas tables.

        Reads multiple raw colocalization results (arg names) for all distances 
        (arg distances) from raw data (workspaces), preprocess this raw data
        and converts it to tables.

        For each colocalization, the preprocessed data is saved in
        two tables (pd.DataFrame). One table contains the data for all
        tomos together and the other for individual tomos. An instance
        of this class is generated and the tables are saved as attributes 
        of this instance. Furthermore, the tables are pickled and saved. 

        The colocalization results are assigned to variables (pandas.DataFrame),
        two for each colocalization. One variable contains data for all
        tomograms together and the other for individual tomograms. Each 
        variable contains results for all distances.

        The variable names are obtained from colocalization names (elements
        of arg names) as follows:
          - coloc_name + '_' + self.join_suffix: all tomograms together
          - coloc_name + '_' + self.individual_suffix: individual tomograms
          - _names: all colocalization names (from arg names)
        They are sorted by tomo name ('_data_syn') and by distance (both).

        If arg columns is not None, the variable containing data from all 
        tomograms together will show only the specified columns. 

        If arg save is True, the variables may be pickled and saved in
        directory specified by arg dir_. If arg force is True, all variables
        are pickled and saved (overwrites files), if force is False, only 
        those variables that were not saved before are saved.

        The pickle file names are obtained by appending '.pkl' to varable names.

        Arguments:
          - names: list of colocalization names
          - distances: list of distances
          - in_path: path to the root of colocalization results
          - mode: defines how to form the paths to the raw colocalization 
          data and defines how to extract tomo id (see extract_data() doc)
          - module: module for the created variables
          - columns: list of dataframe columns present in the tables of the
          returned object (subset of columns present in the raw data)
          - p_values: flag indication if p_values should be calculated
          - random_stats: Flag indicating if basic statistics on random data
          is calculated
          - save: Flag indicating wether the colocalization data 
          (variables) is pickled
          - force: if True, the existing colocalization data pickles
          can be overwriten
          - dir_: directory where the pickled preprocessed tables are written
          - save_formats: (list) formats in which tables are saved 
          (see pyto.io.PandasIO)
          - verbose: Prints info about saved files and data that is not found
          - join_suffix: suffix given to colocalization data tables that 
          contain data for all tomos together
          - individual_suffix: suffix given to colocalization data tables that 
          contain data for individual tomos
        """

        obj = cls(
            join_suffix=join_suffix, individual_suffix=individual_suffix,
            mode=mode, save_formats=save_formats)
        names_local = list(set(names))
        names_local.sort()
        obj._names = names_local
        for nam in names_local:

            # set variable names
            obj_name = nam + '_' + obj.join_suffix
            obj_name_syn = nam + '_' + obj.individual_suffix

            # check if saved already
            if save:
                out_path = os.path.join(dir_, obj_name+'.pkl')
                out_path_syn = os.path.join(dir_, obj_name_syn+'.pkl')
                exists = (
                    (os.path.exists(out_path) and os.path.exists(out_path_syn)))

            # read data
            try:
                data, data_syn = obj.extract_data(
                    name=nam, distances=distances, mode=mode, in_path=in_path,
                    n_sim=n_sim, random_stats=random_stats, p_values=True)  
            except FileNotFoundError as err:
                if verbose:
                    print('Colocalization {} not found'.format(nam))
                    #print(format(err))
                continue
            col_func.calculate_density(data)

            # make variable and save data for all tomos together, if needed
            if save and (force or not exists):
                pdio = PandasIO(
                    file_formats=save_formats, overwrite=force, verbose=verbose)
                pdio.write_table(table=data, base=out_path)
                if verbose:
                    print("Saved colocalization {}".format(nam))
            if columns is not None:
                columns_local = [col for col in columns if col in data.columns]
                data = data[columns_local]
            setattr(obj, obj_name, data)

            # make variable and save data for individual tomos, if needed
            if save and (force or not exists):
                pdio.write_table(table=data_syn, base=out_path_syn)
            setattr(obj, obj_name_syn, data_syn)

        return obj

    @classmethod
    def read_directly(
            cls, name, distance, in_path, mode, index, ids=None, n_sim=None):
        """
        Reads the specified pyseg colocalization workspace directly.

        Used for testing function extract_data() and related.

        Arguments:
          - name: name of the colocalization
          - distance: single distance
          - in_path: root path of the workspaces (pickles)
          - mode: defines how to form the paths to the raw colocalization 
          data and defines how to extract tomo id (see extract_data() doc)
           - index: index of the workspace element that is read
          - ids: tomo ids for which the data is read, if None data for all 
          tomos is read

        Return: dictionary wher keys are tomo ids and values are the data 
        records
        """

        #obj = cls(mode=mode)
        (wspaces, _, _, _) = col_func.set_read_parameters(
            name=name, distances=[distance], in_path=in_path, mode=mode,
            n_sim=n_sim)

        #pkl_path = os.path.join(in_path, wspaces[0])
        pkl_path = wspaces[0]
        pkl_data = pickle.load(open(pkl_path, 'rb'), encoding='latin1')

        data = {}
        for tomo_name, value in pkl_data[index].items():
            syn_id = col_func.get_tomo_id(tomo_name, mode=mode)
            data[syn_id] = value

        result = {}    
        if ids is None:
            result = data
        else:
            for id_ in ids:
                try:
                    value = data[id_]
                except KeyError:
                    value = np.nan
                result[id_] = value

        return result

    def extract_data(
            self, name, distances, in_path, mode='method-1', n_sim=None,
            p_values=True, random_stats=False):
        """Extracts raw data of one pyseg colocalization.

        Extracts raw data for multiple distance (arg distances) of one 
        colocalization raw data specified by (arg name) from workspaces. 

        The data is extracted for each tomo separately and for all 
        tomos together.

        Each raw data workspace contains data for one colocalization 
        and one colocalization distance, and for all tomos. It is a 
        pickled object that is indexed by data index (see 
        coloc_functions.set_read_parameters() code) and by a string that
        contains tomo name (such as tomo path).

        The raw data workspaces have to be located below (arg) in_path and  
        organized depending on (arg) mode, as follows (see :

        mode='method-1':
            3_name/aln_distance/3_name_sim200
            (e.g. 3_set0_set1_set2/aln_15/3_set0_set1_set2_sim200)

        mode='method-1_cr-same':
            3_name/aln_distance_cr_distance/3_name_sim200
            (e.g. 3_set0_set1_set2/aln_15_cr_30/3_set0_set1_set2_sim200)

        mode='method-1_cr-double':
            n_name/aln_distance_cr-coldist/n_name_sim200_wspace.pkl
            (e.g. 2_set0_set2/aln_15_cr-30/2_set0_set2_sim200_wspace.pkl,
            3_set0_set1_set2/aln_15_cr-30/3_set0_set1_set2_sim200_wspace.pkl)

        mode='method-1_cr-double_v2':
            n_name/dist-distance_cr-coldist/n_name_sim-n_sim_wspace.pkl
            (e.g. 2_set1_set2/dist-10_cr-20/3_set1_set2_sim-200_wspace.pkl,
            3set0_set1_set2/dist-20_cr-40/3_set0_set1_set2_sim-200_wspace.pkl)

        mode='simple_cr-double' or mode='munc13':
            n_name/dist-distance_cr-coldist/n_name_sim-n_sim_wspace.pkl
            (e.g. 2_set2_set1/dist-15_cr-30/3_set2_set1_sim-200_wspace.pkl,
            3_set0_set1_set2/dist-15_cr-30/3_set0_set1-set2_sim-200_wspace.pkl)

        where:
          - n: arg name, that is the number of colocalization layers (2 or 3)
          - name: specifies the layers that are aligned (e.g. 
          'pre_tether_pst', or 'pre_tether')
          - n_coloc_name examples: '3_pre_tether_pst', '2_pre_tether'
          - distance: distance (e.g. 15), has to be an element of arg distances 
          - coldist: column_radius_factor * dist (e.g. 30).
          - n-sim: arg n_sim, that is number of simulations (e.g. 200)

        Arg mode also determines how is tomo id (saved in column id) 
        extracted from the tomo file paths specified in raw data workspaces 
        (keys of dictionaries that are pickled to make the raw data 
        workspaces), as follows (see coloc_functions.get_tomo_id()):

        mode='simple_cr-double':
          path = 'dir1/dir2/base_name.ext'
          tomo id = base_name

        mode='munc13':
          path = 'dir1/dir2/foo_syn_tomoid_bin-foo.ext'
          tomo id = tomoid

        all other cases:
          path = 'dir1/dir2/foo_tomoid1_tomoid2_foo.ext'
          tomo id = tomoid1_tomoid2

        Furthermore, if (arg) mode is 'munc13', a default index is used 
        (ints), while in all other cases tomo id (column id) is used as 
        index (implemented in coloc_functions.read_data()).

        Arguments:
          - name: name of the colocalization
          - distances: list of distances
          - in_path: root path to the colocalizationn raw data
          - mode: type of colocalization raw data path
          - p_values: flag indication if p_values should be calculated
          - random_stats: Flag indicating if basic statistics on random data
          is calculated

        Returns data, data_syn:
          - data: data for all synapses together, sorted by tomo names 
          (pandas.DataFrame)
          - data_syn: data for individual synapses, sorted by tomo names and 
          distances (pandas.DataFrame)
        """

        # set mode
        if mode is None:
            mode = self.mode
            if mode is None:
                raise ValueError(
                    "Mode has to be specified as argument or argument")

        # constants related to the organization of data in workspaces
        (in_wspaces, columns, add_columns,
         array_columns) = col_func.set_read_parameters(
             name=name, distances=distances, in_path=in_path, mode=mode,
             n_sim=n_sim)

        # extract data from all workspaces for all distances
        for dist, wspace in zip(distances, in_wspaces):

            # read data from pickles, individual synapses
            data_syn_local = col_func.read_data(
                pkl_path=wspace, columns=columns, mode=mode)
            data_syn_local.insert(
                0, column='distance', value=dist, allow_duplicates=False)
            #data_syn_local = data_syn_local.set_index('distance')

            # calculate p values, individual synapses 
            if p_values:
                data_syn_local = col_func.get_fraction_random(
                    data=data_syn_local)

            # calculate values for all synapses together
            data_local = col_func.aggregate(
                data=data_syn_local, distance=dist, add_columns=add_columns, 
                array_columns=array_columns, p_values=p_values,
                random_stats=random_stats)

            # calculate basic stats for random n subcolumns 
            if random_stats:
                data_local, data_syn_local = col_func.get_random_stats(
                    data=data_local, data_syn=data_syn_local,
                    column='n_subcol_random_all', out_column='n_subcol_random',
                    combine=False)
                data_local, data_syn_local = col_func.get_random_stats(
                    data=data_local, data_syn=data_syn_local,
                    column='n_subcol_random_alt_all', 
                    out_column='n_subcol_random_alt',
                    combine=False)
                data_local, data_syn_local = col_func.get_random_stats(
                    data=data_local, data_syn=data_syn_local,
                    column=['n_subcol_random_all', 'n_subcol_random_alt_all'],
                    out_column='n_subcol_random_combined',
                    combine=True)

            # update 
            try:
                #data = data.append(data_local, ignore_index=True)
                data = pd.concat([data, data_local], ignore_index=True)
            except NameError:
                data = data_local
            try:
                data_syn = pd.concat(
                    [data_syn, data_syn_local], axis=0, ignore_index=True)
            except NameError:
                data_syn = data_syn_local

        # sort by tomo name and distance
        data = data.sort_values(by='distance')
        data_syn = data_syn.sort_values(by=['distance', 'id'])
                
        return data, data_syn 

